{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense, Activation,Dropout\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import model_from_yaml\n",
    "from random import randint\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Corpus:\n",
    "    \"\"\"\n",
    "    Tx       = Time Steps\n",
    "    Vx       = Vocabulary Size or Size of One Hot Encoded Vector for each time step input\n",
    "    m        = Number of Total Examples available in this corpus\n",
    "    XD,YD    = Decoded Feature, Label. Single dimention list of Strings.\n",
    "    XE,YE    = Encoded Feature, Label. Multi dimentional numpy array.\n",
    "    XD.shape = (m,Tx,Vx)\n",
    "    YD.shape = (m,Vx) i.e Tx = 1 for label. Multi input, one output vector.\n",
    "    \"\"\"\n",
    "    def __init__(self, corpus_path):\n",
    "    \n",
    "        with open(corpus_path) as corpus_file:\n",
    "            self.corpus = corpus_file.read()\n",
    "        \n",
    "        self.vocab    = sorted(list(set(self.corpus)))\n",
    "        self.Vx       = len(self.vocab)\n",
    "        \n",
    "        self.encoder  = {c: i for i, c in enumerate(self.vocab)}\n",
    "        self.decoder  = {i: c for i, c in enumerate(self.vocab)}\n",
    "        \n",
    "        self.examples = self.corpus.lower().split('\\n')\n",
    "        np.random.shuffle(self.examples)\n",
    "        \n",
    "        self.Tx       = len(max(self.examples,key=len))\n",
    "        \n",
    "        self.XD,self.YD = self.get_decoded_dataset()\n",
    "        self.XE,self.YE = self.get_encoded_dataset()\n",
    "\n",
    "    def get_decoded_dataset(self):        \n",
    "        X = []\n",
    "        Y = []\n",
    "        for name in self.examples:\n",
    "            if (len(name) == 0):\n",
    "                continue\n",
    "            x = name[0]\n",
    "            for c in name[1:]:\n",
    "                X.append(x)\n",
    "                Y.append(c)\n",
    "                x = x + c\n",
    "            X.append(name)\n",
    "            Y.append('\\n')\n",
    "        self.m = len(X)\n",
    "        return X,Y\n",
    "    \n",
    "    def get_encoded_dataset(self):\n",
    "        X = np.zeros((self.m,self.Tx,self.Vx))\n",
    "        Y = np.zeros((self.m,self.Vx))\n",
    "        for i in range(self.m):\n",
    "            x = self.XD[i]\n",
    "            y = self.YD[i]\n",
    "            for j in range(self.Tx):\n",
    "                if(j<len(x)):\n",
    "                    #print('i=',i,'x=',x,'j=',j,'x[j]=',x[j:j+1])\n",
    "                    idx = self.encoder[x[j:j+1]]\n",
    "                    X[i,j,idx] = 1\n",
    "                else:\n",
    "                    X[i,j,self.encoder['\\n']] = 1  ## Use some rarely used char in dataset.\n",
    "            Y[i,self.encoder[y[0]]] = 1\n",
    "        return X,Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "metadata": {},
   "outputs": [],
   "source": [
    "crp = Corpus('data/babynames.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "decoded X = greg Y = o \n",
      "encoded X = greg Y = o \n",
      "decoded X = harro Y = l \n",
      "encoded X = harro Y = l \n",
      "decoded X = had Y = r \n",
      "encoded X = had Y = r \n",
      "decoded X = l Y = e \n",
      "encoded X = l Y = e \n",
      "decoded X = jerry Y = \n",
      " \n",
      "encoded X = jerry Y = \n",
      " \n",
      "decoded X = m Y = a \n",
      "encoded X = m Y = a \n",
      "decoded X = w Y = a \n",
      "encoded X = w Y = a \n",
      "decoded X = m Y = a \n",
      "encoded X = m Y = a \n",
      "decoded X = m Y = o \n",
      "encoded X = m Y = o \n",
      "decoded X = ken Y = \n",
      " \n",
      "encoded X = ken Y = \n",
      " \n",
      "decoded X = be Y = r \n",
      "encoded X = be Y = r \n",
      "decoded X = sh Y = a \n",
      "encoded X = sh Y = a \n",
      "decoded X = keena Y = n \n",
      "encoded X = keena Y = n \n",
      "decoded X = sherl Y = i \n",
      "encoded X = sherl Y = i \n",
      "decoded X = doe Y = \n",
      " \n",
      "encoded X = doe Y = \n",
      " \n",
      "decoded X = cassan Y = d \n",
      "encoded X = cassan Y = d \n",
      "decoded X = concetti Y = n \n",
      "encoded X = concetti Y = n \n",
      "decoded X = kri Y = s \n",
      "encoded X = kri Y = s \n",
      "decoded X = ali Y = s \n",
      "encoded X = ali Y = s \n",
      "decoded X = jacqu Y = e \n",
      "encoded X = jacqu Y = e \n"
     ]
    }
   ],
   "source": [
    "for a in range(20):\n",
    "    r = randint(0,crp.m)\n",
    "    x = ''\n",
    "    for i in range(crp.Tx):\n",
    "        c = crp.decoder[np.argmax(crp.XE[r,i,:])]\n",
    "        if (c == '\\n'): break\n",
    "        x = x + c\n",
    "    y = crp.decoder[np.argmax(crp.YE[r,:])]\n",
    "    \n",
    "    print('decoded X = {} Y = {} '.format(crp.XD[r],crp.YD[r]))\n",
    "    print('encoded X = {} Y = {} '.format(x,y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Transform X data (m,Tx,vec_size) to Y (m,1,vec_size) i.e (m,vec_size).\n",
    "- Many to One RNN architecture\n",
    "- Lets convert into one hot encoding\n",
    "- LSTM model will remove Tx dimension if you don't specify return_sequences=True.\n",
    "- In the predict, you can pass a random text of length upto Tx to kick start the prediction. Loop it after it gives each word.\n",
    "- "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CRNN:\n",
    "    \n",
    "    def __init__(self,Tx,Vx,encoder,decoder):\n",
    "        self.Tx  = Tx\n",
    "        self.Vx  = Vx\n",
    "        self.encoder       = encoder\n",
    "        self.decoder       = decoder\n",
    "        \n",
    "    def build(self,units,layers=1,dropout=None):\n",
    "        model = Sequential()\n",
    "\n",
    "        for i in range(layers):\n",
    "            if(layers == 1):\n",
    "                model.add(LSTM(units, input_shape=(self.Tx, self.Vx)))\n",
    "            elif(i == 0): \n",
    "                model.add(LSTM(units, input_shape=(self.Tx, self.Vx),return_sequences=True))\n",
    "            elif(i != layers -1):\n",
    "                model.add(LSTM(units, return_sequences=True))\n",
    "            else:\n",
    "                model.add(LSTM(units))\n",
    "\n",
    "            if(dropout is not None):\n",
    "                model.add(Dropout(dropout))\n",
    "                    \n",
    "        model.add(Dense(self.Vx))\n",
    "        model.add(Activation('softmax'))\n",
    "        \n",
    "        model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
    "        self.model = model\n",
    "        self.model.summary()\n",
    "    \n",
    "    def load(self,mfile,cpfile):\n",
    "        with open(mfile) as model_file:\n",
    "            architecture = model_file.read()\n",
    "\n",
    "        self.model = model_from_yaml(architecture)\n",
    "        self.model.load_weights(cpfile)\n",
    "        self.model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
    "        self.model.summary()\n",
    "        \n",
    "    def train(self,mfile,cpfile,X_train,Y_train,epochs,batch_size):\n",
    "        architecture = self.model.to_yaml()\n",
    "        with open(mfile, 'w') as model_file:\n",
    "            model_file.write(architecture)\n",
    "\n",
    "        file_path= cpfile + \"-checkpoint-{epoch:02d}-{loss:.3f}.hdf5\"\n",
    "        checkpoint = ModelCheckpoint(file_path, monitor=\"loss\", verbose=1, save_best_only=True, mode=\"min\")\n",
    "        callbacks = [checkpoint]\n",
    "\n",
    "        self.model.fit(X_train, Y_train, epochs=epochs, batch_size=batch_size, callbacks=callbacks)\n",
    "    \n",
    "    def get_encoded_data(self,text):\n",
    "        X = np.zeros((1, self.Tx, self.Vx), dtype=np.bool)\n",
    "        for i, c in enumerate(text):\n",
    "            X[0, i, self.encoder[c]] = 1    \n",
    "        return X\n",
    "\n",
    "    def generate(self, text,cnt):        \n",
    "        ret = []\n",
    "        for t in range(cnt):\n",
    "            generated_text = text\n",
    "            for i in range(self.Tx-(len(text))):\n",
    "                X = self.get_encoded_data(generated_text)\n",
    "                prediction = self.model.predict(X, verbose=0)\n",
    "                prediction = np.random.choice(self.Vx,p=prediction.ravel())\n",
    "                if(prediction == 0):\n",
    "                    break\n",
    "                generated_text += self.decoder[prediction]\n",
    "            ret.append(generated_text)\n",
    "        return ret\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_26 (LSTM)               (None, 256)               320512    \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 56)                14392     \n",
      "_________________________________________________________________\n",
      "activation_19 (Activation)   (None, 56)                0         \n",
      "=================================================================\n",
      "Total params: 334,904\n",
      "Trainable params: 334,904\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "47925/47925 [==============================] - 45s 934us/step - loss: 2.5924\n",
      "\n",
      "Epoch 00001: loss improved from inf to 2.59240, saving model to babynames_model-checkpoint-01-2.592.hdf5\n",
      "Epoch 2/20\n",
      "47925/47925 [==============================] - 37s 772us/step - loss: 2.3956\n",
      "\n",
      "Epoch 00002: loss improved from 2.59240 to 2.39561, saving model to babynames_model-checkpoint-02-2.396.hdf5\n",
      "Epoch 3/20\n",
      "47925/47925 [==============================] - 37s 778us/step - loss: 2.33490s - loss: \n",
      "\n",
      "Epoch 00003: loss improved from 2.39561 to 2.33493, saving model to babynames_model-checkpoint-03-2.335.hdf5\n",
      "Epoch 4/20\n",
      "47925/47925 [==============================] - 37s 768us/step - loss: 2.2521\n",
      "\n",
      "Epoch 00004: loss improved from 2.33493 to 2.25207, saving model to babynames_model-checkpoint-04-2.252.hdf5\n",
      "Epoch 5/20\n",
      "47925/47925 [==============================] - 39s 819us/step - loss: 2.2067\n",
      "\n",
      "Epoch 00005: loss improved from 2.25207 to 2.20673, saving model to babynames_model-checkpoint-05-2.207.hdf5\n",
      "Epoch 6/20\n",
      "47925/47925 [==============================] - 46s 969us/step - loss: 2.1578\n",
      "\n",
      "Epoch 00006: loss improved from 2.20673 to 2.15780, saving model to babynames_model-checkpoint-06-2.158.hdf5\n",
      "Epoch 7/20\n",
      "47925/47925 [==============================] - 43s 904us/step - loss: 2.0882\n",
      "\n",
      "Epoch 00007: loss improved from 2.15780 to 2.08816, saving model to babynames_model-checkpoint-07-2.088.hdf5\n",
      "Epoch 8/20\n",
      "47925/47925 [==============================] - 46s 959us/step - loss: 2.0230\n",
      "\n",
      "Epoch 00008: loss improved from 2.08816 to 2.02296, saving model to babynames_model-checkpoint-08-2.023.hdf5\n",
      "Epoch 9/20\n",
      "47925/47925 [==============================] - 43s 894us/step - loss: 1.9684\n",
      "\n",
      "Epoch 00009: loss improved from 2.02296 to 1.96836, saving model to babynames_model-checkpoint-09-1.968.hdf5\n",
      "Epoch 10/20\n",
      "47925/47925 [==============================] - 44s 925us/step - loss: 1.9193\n",
      "\n",
      "Epoch 00010: loss improved from 1.96836 to 1.91926, saving model to babynames_model-checkpoint-10-1.919.hdf5\n",
      "Epoch 11/20\n",
      "47925/47925 [==============================] - 52s 1ms/step - loss: 1.8729\n",
      "\n",
      "Epoch 00011: loss improved from 1.91926 to 1.87294, saving model to babynames_model-checkpoint-11-1.873.hdf5\n",
      "Epoch 12/20\n",
      "47925/47925 [==============================] - 49s 1ms/step - loss: 1.8316\n",
      "\n",
      "Epoch 00012: loss improved from 1.87294 to 1.83158, saving model to babynames_model-checkpoint-12-1.832.hdf5\n",
      "Epoch 13/20\n",
      "47925/47925 [==============================] - 47s 984us/step - loss: 1.7920\n",
      "\n",
      "Epoch 00013: loss improved from 1.83158 to 1.79198, saving model to babynames_model-checkpoint-13-1.792.hdf5\n",
      "Epoch 14/20\n",
      "47925/47925 [==============================] - 49s 1ms/step - loss: 1.7576\n",
      "\n",
      "Epoch 00014: loss improved from 1.79198 to 1.75761, saving model to babynames_model-checkpoint-14-1.758.hdf5\n",
      "Epoch 15/20\n",
      "47925/47925 [==============================] - 51s 1ms/step - loss: 1.7211\n",
      "\n",
      "Epoch 00015: loss improved from 1.75761 to 1.72108, saving model to babynames_model-checkpoint-15-1.721.hdf5\n",
      "Epoch 16/20\n",
      "47925/47925 [==============================] - 54s 1ms/step - loss: 1.6897\n",
      "\n",
      "Epoch 00016: loss improved from 1.72108 to 1.68972, saving model to babynames_model-checkpoint-16-1.690.hdf5\n",
      "Epoch 17/20\n",
      "47925/47925 [==============================] - 53s 1ms/step - loss: 1.6566\n",
      "\n",
      "Epoch 00017: loss improved from 1.68972 to 1.65658, saving model to babynames_model-checkpoint-17-1.657.hdf5\n",
      "Epoch 18/20\n",
      "47925/47925 [==============================] - 51s 1ms/step - loss: 1.6270\n",
      "\n",
      "Epoch 00018: loss improved from 1.65658 to 1.62695, saving model to babynames_model-checkpoint-18-1.627.hdf5\n",
      "Epoch 19/20\n",
      "47925/47925 [==============================] - 53s 1ms/step - loss: 1.6016\n",
      "\n",
      "Epoch 00019: loss improved from 1.62695 to 1.60159, saving model to babynames_model-checkpoint-19-1.602.hdf5\n",
      "Epoch 20/20\n",
      "47925/47925 [==============================] - 53s 1ms/step - loss: 1.5739\n",
      "\n",
      "Epoch 00020: loss improved from 1.60159 to 1.57387, saving model to babynames_model-checkpoint-20-1.574.hdf5\n",
      "[\"xqrDJw'CYTIM'lq\", 'xndkklgdoqhrmIW', 'xrdShOzW', \"xxU 'd'Zx'xX''M\", \"xxzV zddbx'VZT'\", \"xdxzq''TQQM'DxO\", \"xFgS'cxM'''FG'U\", 'xdqE iOoz', \"xkwEZ MxW'''Yxx\", \"xddjyDCMPZ'IW' \", \"x xGZ'x x'T'Ik \", \"xdasdUn'SeL\", \"xdPAkd'M'UVCG'C\", \"xnxdB 'MV'\", 'xd  ', \"xclOwj'VkZD'E''\", \"xx'Tqq'PD'yTVMF\", \"xdx' x'BJLOA'B'\", \"xcxo''xrzNrHGIZ\", 'xRFd', \"xx'C''jj'BRSPmI\", 'xQz', \"xdPrxKx'LR'''''\", \"xddcey'PsKiDMG \", \"xrpdUadaL xW' '\", \"xdx''xWYOI'D'gT\", 'x', \"xdddgocsqI E'''\", 'xdos', \"xem's''-WA BKng\", 'xcj-drAFrUAMYKX', \"xlkkspcDB'jwI'L\", \"xcczwRWx'IGIDV'\", \"xjoswN''PH Cq''\", 'xa', 'xd', \"xzdsgBcOBx'VjE'\", \"xxpCd gMC''Ttb'\", \"xd'z\", \"xbkx'RgY'A'M  k\", 'xlo', \"xklkcdZc-'dboed\", 'xze', \"xdx''''' Ta'xvY\", 'xab', \"xdmTST''qZ'kE k\", \"xxFEzAxR'''Tqe'\", 'xddnddd', \"xdFq'E\", \"xqiknxVu'tGB'A'\", 'xdr', \"xd'ckPk'''ZY''R\", 'xcQXddzwwNhLzHZ', \"xc'c\", 'x', \"xpj'rfEc''UOcc-\", \"xxZxM '''VQZ'xD\", \"xxdCPx'K'W'W'''\", 'xV', 'xCu', \"xdlx'eB'JWAcz-e\", \"xcWdkxr'xI''ZDT\", \"xTxUd'''cF''F''\", 'xa', \"xdxC' p'BWL'z'E\", 'x', \"xkxB'xXGf'GMPIB\", 'xd', \"xdwx''E''U'' G-\", 'xdldodqhhdCZ', \"xdS'dc'X' h'RMd\", \"xBdd''\", 'xdesrl', \"xxI'O DTdbFazJ'\", \"xzcx''ObxMzTxUR\", 'x', \"xxO dY'Qxw'RxGF\", \"xdx'I'VN'WPY'R'\", \"xBdKdhcTg 'qe''\", \"xcdiRRUo'IMXRPF\", 'xdd', 'xeauzu', \"xqyxYE'' ' SI'I\", 'xdVc', \"xDdd''xU'Igx'GI\", \"xd'YdkYx'\", \"xdd'dFAk''oS' d\", 'x', 'xdo', \"x'd'qBCgA'p'QCT\", \"xdosdqqouk'y\", 'xehslld', 'xca', \"xzcMVNdL'dIXrI\", \"xMOdxFgI M'M-gx\", 'xko', 'xZ skol d', \"xBdc'gMw 'U'zFK\", \"xRx'pq'jr'\", \"xDd'do\"]\n"
     ]
    }
   ],
   "source": [
    "crp = Corpus('data/babynames.txt')\n",
    "m  = crp.m\n",
    "Vx = crp.Vx\n",
    "Tx = crp.Tx\n",
    "\n",
    "net = CRNN(Tx,Vx,crp.encoder,crp.decoder)\n",
    "\n",
    "X_train,Y_train = crp.get_encoded_dataset()\n",
    "net.build(256,layers=1)\n",
    "net.train('babynames_model.yaml','babynames_model',X_train,Y_train,epochs=20,batch_size=128)\n",
    "\n",
    "\n",
    "\n",
    "#net.load('babynames_model.yaml','babynames_model-checkpoint-20-1.822.hdf5')\n",
    "print(net.generate('x',100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_25 (LSTM)               (None, 256)               293888    \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 30)                7710      \n",
      "_________________________________________________________________\n",
      "activation_18 (Activation)   (None, 30)                0         \n",
      "=================================================================\n",
      "Total params: 301,598\n",
      "Trainable params: 301,598\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "net.load('babynames_model.yaml','babynames_model-checkpoint-20-1.504.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_24 (LSTM)               (None, 256)               320512    \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 56)                14392     \n",
      "_________________________________________________________________\n",
      "activation_17 (Activation)   (None, 56)                0         \n",
      "=================================================================\n",
      "Total params: 334,904\n",
      "Trainable params: 334,904\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "net.load('babynames_model-best.yaml','babynames_model-checkpoint-best.hdf5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['mad', 'mad', 'madgqi', 'madyn', 'mad', \"madgdF'SIYJE'G'\", \"madkp'al\", 'madhgq', 'madsashUSBLSAwJ', \"madm'l'jjgQD kO\", 'mad', \"maddShhw'AglB\", 'mad', 'mad', 'mad', 'mad', 'madtcsoJdjUrNqr', 'mad', 'madgqZe ', 'mad', 'madkl', 'madi', 'maded', 'madhuwfoDVWCApS', 'mad', 'mad', \"maddSa'NKMUKXNF\", 'mad', 'madduCKld', 'mad', 'mad', 'mad', 'mad', 'mad', 'mad', 'madsarhr', 'madkl', 'mad', 'mad', 'mad', \"maddZUPhPsqWAR'\", 'mad', 'madyutWIOoWNurI', 'mad', 'mad', 'mad', \"madyoA'M-zm-\", 'mad', 'mad', 'mad', 'madpaNOzSzXUZLK', 'mad', 'mad', 'madatsehfaQfJXX', 'mad', 'madhrkhhrhhIkSQ', 'mad-i', 'mad', 'mad', 'madh', 'mad', 'mad', 'mad', 'mad', 'mad', 'mad', \"madgBu''a''\", 'mad', 'mad', 'mad', 'mad', 'mad', 'mad', 'mad', 'mad', \"madyndDxJ'VJAOY\", \"madie'oBoMdctE\", 'mad', 'madrkdghwWUWjAE', 'maddaNMRJSCLFGR', 'madi', 'madn', 'mad', 'mad', 'mad', 'mad', 'mad', 'mad', 'madhuVcwK', 'mad', 'mad', 'maddlk', 'madddCgICHWVUIg', 'maddVlehrweGoEI', \"madd'huLShPXhMF\", 'mad', 'mad', 'mad', 'maded', 'mad']\n"
     ]
    }
   ],
   "source": [
    "print(net.generate('mad',100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['madiesa', 'madabi', 'mada', 'madidh', 'madelia', 'mades', 'madia', 'madeline', 'madvin', 'madra', 'mady', 'madarito', 'maddive', 'madrey', 'made', 'madon', 'madfie', 'madra', 'madth', 'madie', 'madrecha', 'madiniv', 'madraine', 'madyna', 'madet', 'madwerda', 'maddasyn', 'madia', 'madeli', 'madry', 'madfuse', 'madrie', 'maddae', 'maddy', 'madaie', 'madisa', 'madrena', 'madele', 'madrick', 'madie', 'madoraile', 'maddyla', 'maddiha', 'maderite', 'madilie', 'madre', 'madi', 'madive', 'madiausa', 'madies', 'madesti', 'madlor', 'madarice', 'madabore', 'madelee', 'madio', 'madgace', 'madde', 'madgich', 'madtor', 'madbise', 'madlia', 'mad', 'made', 'madesta', 'mady', 'madal', 'madala', 'madel', 'madete', 'madlis', 'madbelle', 'madeline', 'madsy', 'madibol', 'madia', 'madd', 'madimild', 'madelezga', 'madminu', 'madyar', 'madfel', 'madtomias', 'madelie', 'madi', 'madteo', 'madele', 'mada', 'madeline', 'madgae', 'madmin', 'madele', 'madelie', 'madlinse', 'madrayah', 'made', 'madrudlen', 'maddasina', 'madgelle', 'madelene']\n"
     ]
    }
   ],
   "source": [
    "print(net.generate('mad',100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
