{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center> Generate baby names </center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keras with TF background"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-21T12:09:16.308479Z",
     "start_time": "2018-11-21T12:09:14.632084Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/pai/home/kmadhu/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense, Activation,Dropout\n",
    "from keras.callbacks import ModelCheckpoint,Callback\n",
    "from keras.utils import to_categorical,multi_gpu_model\n",
    "from keras.models import model_from_yaml\n",
    "from random import randint\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Corpus\n",
    "    - data    : raw string input data\n",
    "    - vocab   : vocabulary\n",
    "    - encoder : python dictionary. { 'char' : index }\n",
    "    - decoder : python dictionary. { index  : 'char'}\n",
    "    - Tx      : timestep\n",
    "    - m       : Number of samples\n",
    "    - Vx      : Length of the vocabular or Channel Length after encoding\n",
    "    - X       : Features\n",
    "    - Y       : Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-21T12:09:18.179821Z",
     "start_time": "2018-11-21T12:09:18.162453Z"
    }
   },
   "outputs": [],
   "source": [
    "class corpus:\n",
    "    def __init__(self):\n",
    "        self.data    = \"\"\n",
    "        self.vocab   = \"\"\n",
    "        \n",
    "        self.encoder = None\n",
    "        self.decoder = None\n",
    "        \n",
    "        self.Tx      = 0\n",
    "        self.m       = 0\n",
    "        self.Vx      = 0\n",
    "        \n",
    "        self.X       = []\n",
    "        self.Y       = []\n",
    "        \n",
    "    def __str__(self):\n",
    "        s = ''\n",
    "        s += f'Number of Examples  m  = {self.m}\\n'\n",
    "        s += f'Number of Timesteps Tx = {self.Tx}\\n'\n",
    "        s += f'Vocabulary Length   Vx = {self.Vx}\\n'\n",
    "        return s\n",
    "     \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-21T12:09:18.828516Z",
     "start_time": "2018-11-21T12:09:18.826893Z"
    }
   },
   "outputs": [],
   "source": [
    "# crp = corpus() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read the file to populate data and vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-21T12:09:19.994127Z",
     "start_time": "2018-11-21T12:09:19.989924Z"
    }
   },
   "outputs": [],
   "source": [
    "def load_data(fpath):\n",
    "    with open(fpath) as corpus_file:\n",
    "        data = corpus_file.read().lower()\n",
    "    vocab = sorted(list(set(data)))\n",
    "    return data,vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-21T12:09:20.571866Z",
     "start_time": "2018-11-21T12:09:20.570000Z"
    }
   },
   "outputs": [],
   "source": [
    "# crp.data,crp.vocab  = load_data('data/babynames.txt')\n",
    "# print(\"data sample = '{}' data len = {} vocab = {} vocab_len = {}\".\n",
    "#               format(crp.data[0:20],len(crp.data), crp.vocab,len(crp.vocab)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Encoder and Decoders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-21T12:09:21.891702Z",
     "start_time": "2018-11-21T12:09:21.888118Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_encoder(crp):\n",
    "    return {c: i for i, c in enumerate(crp.vocab)}\n",
    "def get_decoder(crp):\n",
    "    return {i: c for i, c in enumerate(crp.vocab)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-21T12:09:22.854556Z",
     "start_time": "2018-11-21T12:09:22.852893Z"
    }
   },
   "outputs": [],
   "source": [
    "# crp.encoder = get_encoder(crp)\n",
    "# crp.decoder = get_decoder(crp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Slice the continous text data into list of features and Labels\n",
    " - For each name, prepend space so that each name of time step size.\n",
    " - Slide the window by one character until we get space\n",
    " - Tx = max(len(names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-21T12:09:24.252423Z",
     "start_time": "2018-11-21T12:09:24.238918Z"
    }
   },
   "outputs": [],
   "source": [
    "def slice_name(name,Tx):\n",
    "    X=[]\n",
    "    Y=[]\n",
    "    name=\"%*s\"%(Tx,name)+'\\n'\n",
    "    for i in range(Tx):\n",
    "        if(name[:-1][-1] == ' '):\n",
    "            break\n",
    "        x=name[:-1]\n",
    "        y=name[-1]\n",
    "        X.append(x)\n",
    "        Y.append(y)\n",
    "        name = ' ' + name[:-1]\n",
    "    X.reverse()\n",
    "    Y.reverse()\n",
    "    return X,Y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-21T12:09:24.876655Z",
     "start_time": "2018-11-21T12:09:24.874888Z"
    }
   },
   "outputs": [],
   "source": [
    "# X,Y = slice_name('madhu',5)\n",
    "# for x,y in zip(X,Y):\n",
    "#     print(x,y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-21T12:09:25.922025Z",
     "start_time": "2018-11-21T12:09:25.913175Z"
    }
   },
   "outputs": [],
   "source": [
    "def slice_data(data):\n",
    "    samples = data.split('\\n')\n",
    "    np.random.shuffle(samples)\n",
    "    Tx = len(max(samples,key=len))\n",
    "    feature = []\n",
    "    label   = []\n",
    "    for name in samples:\n",
    "        x,y = slice_name(name,Tx)\n",
    "        feature = feature + x\n",
    "        label   = label + y\n",
    "    return feature,label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-21T12:09:26.923406Z",
     "start_time": "2018-11-21T12:09:26.921741Z"
    }
   },
   "outputs": [],
   "source": [
    "# crp.X,crp.Y = slice_data(crp.data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-21T12:09:27.627723Z",
     "start_time": "2018-11-21T12:09:27.625881Z"
    }
   },
   "outputs": [],
   "source": [
    "# for i in range(3):\n",
    "#     r = randint(1,len(crp.X))\n",
    "#     print(f\"X[{r}] = {crp.X[r]} Y[{r}] = {crp.Y[r]}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Update parameters (Tx, Vx, m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-21T12:09:29.022909Z",
     "start_time": "2018-11-21T12:09:29.021033Z"
    }
   },
   "outputs": [],
   "source": [
    "# crp.Tx = len(crp.X[0])\n",
    "# crp.Vx = len(crp.vocab)\n",
    "# crp.m      = len(crp.X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-21T12:09:29.658904Z",
     "start_time": "2018-11-21T12:09:29.657314Z"
    }
   },
   "outputs": [],
   "source": [
    "# print(crp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-21T07:03:01.353919Z",
     "start_time": "2018-11-21T07:03:01.352178Z"
    }
   },
   "source": [
    "## Feature Engineering\n",
    "    - Transform X data (m,Tx,Vx) to Y (m,1,Vx) i.e (m,Vx).\n",
    "    - Many to One RNN architecture\n",
    "    - Lets convert into one hot encoding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-21T12:09:30.839209Z",
     "start_time": "2018-11-21T12:09:30.823093Z"
    }
   },
   "outputs": [],
   "source": [
    "def encode_data(crp):        \n",
    "    # First each char after Tx, we will have one example.\n",
    "    feature = np.zeros((crp.m,crp.Tx))\n",
    "    label   = np.zeros(crp.m)\n",
    "        \n",
    "    for i in range (0, crp.m, 1):\n",
    "        sentence  = crp.X[i]\n",
    "        next_char = crp.Y[i]\n",
    "            \n",
    "        for j in range(crp.Tx):\n",
    "            feature[i,j] = crp.encoder[sentence[j]]\n",
    "            label[i]     = crp.encoder[next_char]\n",
    "\n",
    "    feature = to_categorical(feature,num_classes=crp.Vx)\n",
    "    label   = to_categorical(label,num_classes=crp.Vx)\n",
    "    return feature,label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-21T12:09:31.592889Z",
     "start_time": "2018-11-21T12:09:31.590979Z"
    }
   },
   "outputs": [],
   "source": [
    "# X,Y = encode_data(crp)\n",
    "\n",
    "# print(\"Sliced our corpus into {} examples. feature.shape (m,Tx,Vx) = {} label.shape (m,Vx) = {}\".\n",
    "#         format(crp.m, X.shape,Y.shape))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Model\n",
    "    - LSTM model will remove Tx dimension if you don't specify return_sequences=True.\n",
    "    - In the predict, you can pass a random text of length upto Tx to kick start the prediction. Loop it after it gives each word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-21T12:09:34.509792Z",
     "start_time": "2018-11-21T12:09:34.485028Z"
    }
   },
   "outputs": [],
   "source": [
    "def build_LSTM_model(units,Tx,Vx,layers=1,dropout=None):\n",
    "    model = Sequential()\n",
    "    for i in range(layers):\n",
    "        if(layers == 1):\n",
    "            model.add(LSTM(units, input_shape=(Tx,Vx)))\n",
    "        elif(i == 0): \n",
    "            model.add(LSTM(units, input_shape=(Tx,Vx),return_sequences=True))\n",
    "        elif(i != layers -1):\n",
    "            model.add(LSTM(units, return_sequences=True))\n",
    "        else:\n",
    "            model.add(LSTM(units))\n",
    "\n",
    "        if(dropout is not None):\n",
    "            model.add(Dropout(dropout))\n",
    "                    \n",
    "    model.add(Dense(Vx))\n",
    "    model.add(Activation('softmax'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-21T12:09:35.384003Z",
     "start_time": "2018-11-21T12:09:35.382009Z"
    }
   },
   "outputs": [],
   "source": [
    "# model = build_LSTM_model(256,crp.Tx,crp.Vx)\n",
    "# model.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference Logic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-21T12:49:33.600811Z",
     "start_time": "2018-11-21T12:49:33.563345Z"
    }
   },
   "outputs": [],
   "source": [
    "def generate_text(model, crp, seed_text,cnt):\n",
    "\n",
    "    def get_encoded_data(text):\n",
    "        X = np.zeros((1, crp.Tx, crp.Vx), dtype=np.bool)\n",
    "        for i, c in enumerate(text):\n",
    "            X[0, i, crp.encoder[c]] = 1    \n",
    "        return X\n",
    "\n",
    "    ret = []\n",
    "    \n",
    "    for t in range(cnt):\n",
    "        if(seed_text is None):\n",
    "            generated_text = ''+crp.decoder[randint(1,crp.Vx-1)]\n",
    "        else:\n",
    "            generated_text = seed_text\n",
    "        for i in range(crp.Tx):\n",
    "            generated_text =\"%*s\"%(crp.Tx,generated_text)\n",
    "            X = get_encoded_data(generated_text)\n",
    "            prediction = model.predict(X, verbose=0)\n",
    "            #prediction = crp.decoder[np.argmax(prediction)]\n",
    "            prediction = crp.decoder[np.random.choice(crp.Vx,p=prediction.ravel())]\n",
    "            if(prediction == '\\n'):\n",
    "                break\n",
    "            generated_text = generated_text.strip() + prediction  \n",
    "        ret.append(generated_text.strip())\n",
    "    return ret\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom call back to save the final best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-21T12:09:38.526529Z",
     "start_time": "2018-11-21T12:09:38.502873Z"
    }
   },
   "outputs": [],
   "source": [
    "class mycallback(Callback):\n",
    "    def __init__(self,crp,model_path):\n",
    "        super(mycallback, self).__init__()\n",
    "        self.best_model = None\n",
    "        self.best_loss  = 1000\n",
    "        self.best_epoch = -1\n",
    "        self.model_path = model_path\n",
    "        \n",
    "    def on_train_end(self, logs={}):\n",
    "        print(f'saving the model with loss = {self.best_loss} on epoch {self.best_epoch}')\n",
    "        self.best_model.save(self.model_path)\n",
    "        return\n",
    " \n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        loss = logs['loss']\n",
    "        if(loss < self.best_loss):\n",
    "            self.best_model = self.model\n",
    "            self.best_loss  = loss\n",
    "            self.best_epoch = epoch\n",
    "            print(generate_text(self.model,crp,None,10))\n",
    "        return \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-21T12:09:54.695723Z",
     "start_time": "2018-11-21T12:09:54.693946Z"
    }
   },
   "outputs": [],
   "source": [
    "# hist = model.fit(X, Y, epochs=30, batch_size=128, callbacks=[mycallback(crp,'babynames-best.h5')])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <center> Execution </center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and Preprocess Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-21T12:10:11.401077Z",
     "start_time": "2018-11-21T12:10:09.951062Z"
    }
   },
   "outputs": [],
   "source": [
    "crp                 = corpus()\n",
    "crp.data,crp.vocab  = load_data('data/babynames.txt')\n",
    "crp.encoder         = get_encoder(crp)\n",
    "crp.decoder         = get_decoder(crp)\n",
    "\n",
    "\n",
    "crp.X,crp.Y         = slice_data(crp.data)\n",
    "crp.Tx              = len(crp.X[0])\n",
    "crp.Vx              = len(crp.vocab)\n",
    "crp.m               = len(crp.X)\n",
    "\n",
    "X,Y = encode_data(crp)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-21T09:06:22.676658Z",
     "start_time": "2018-11-21T09:06:22.674682Z"
    }
   },
   "source": [
    "## create the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-21T12:10:19.363623Z",
     "start_time": "2018-11-21T12:10:19.056302Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1 (LSTM)                (None, 256)               293888    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 30)                7710      \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 30)                0         \n",
      "=================================================================\n",
      "Total params: 301,598\n",
      "Trainable params: 301,598\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = build_LSTM_model(256,crp.Tx,crp.Vx)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-21T12:16:29.965506Z",
     "start_time": "2018-11-21T12:10:45.719979Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "47909/47909 [==============================] - 17s 351us/step - loss: 2.4252\n",
      "['-peszla', 'barde', 'ekybe', 'cagjiek', 'ricna', 'vgynlle', 'penderite', 'elbentol', 'yrincon', 'rbielieb']\n",
      "Epoch 2/30\n",
      "47909/47909 [==============================] - 11s 232us/step - loss: 2.1216\n",
      "['quoda', 'oly', 'garmy', 'frker', 'wagdet', 'salmeta', 'nan', 'inkestan', 'eadrine', 'wah']\n",
      "Epoch 3/30\n",
      "47909/47909 [==============================] - 11s 236us/step - loss: 2.0309\n",
      "['erasia', 'quanana', 'xinsie', 'bertda', 'sashvor', 'zoleina', 'sabery', 'calda', 'gelbiag', 'audusta']\n",
      "Epoch 4/30\n",
      "47909/47909 [==============================] - 11s 237us/step - loss: 1.9717\n",
      "['ebelin', 'fryretta', 'ynchassia', 'rricy', 'oren', 'anella', 'kash', \"'per\", 'otabelta', 'rine']\n",
      "Epoch 5/30\n",
      "47909/47909 [==============================] - 11s 233us/step - loss: 1.9240\n",
      "['-lulike', 'cherolul', 'yderrey', 'ashorina', 'list', 'zolbeyt', 'osbaoni', 'veve', 'usora', 'nanona']\n",
      "Epoch 6/30\n",
      "47909/47909 [==============================] - 11s 234us/step - loss: 1.8762\n",
      "[\"'uste\", 'himv', 'jeay', 'zanay', 'aneshell', 'will', 'porli', 'elexine', 'alvard', 'wolly']\n",
      "Epoch 7/30\n",
      "47909/47909 [==============================] - 11s 228us/step - loss: 1.8329\n",
      "['-ebbethelia', 'ren', \"'amoys\", 'iah', 'waves', 'essamunth', 'elina', 'aligkos', 'netoria', 'la']\n",
      "Epoch 8/30\n",
      "47909/47909 [==============================] - 11s 230us/step - loss: 1.7893\n",
      "['yvolyn', 'zeron', \"'loet\", 'maliere', 'jusa', 'nuistina', 'annalone', 'yyne', 'udy', 'sabel']\n",
      "Epoch 9/30\n",
      "47909/47909 [==============================] - 10s 218us/step - loss: 1.7479\n",
      "['odie', 'ven', 'xyseonens', '-ulossa', 'ursil', 'meressa', 'lened', 'tobe', 'phena', 'jussita']\n",
      "Epoch 10/30\n",
      "47909/47909 [==============================] - 11s 233us/step - loss: 1.7081\n",
      "['berandie', 'farnadia', 'nitane', 'rixw', 'inni', 'perron', 'andaly', 'jenisa', '-ugrett', 'aghe']\n",
      "Epoch 11/30\n",
      "47909/47909 [==============================] - 11s 221us/step - loss: 1.6705\n",
      "['hulifab', 'bindis', 'inda', 'zaur', 'fridelia', 'pizsy', 'tars', 'nial', 'yrone', 'jicey']\n",
      "Epoch 12/30\n",
      "47909/47909 [==============================] - 11s 230us/step - loss: 1.6342\n",
      "['noraca', 'katia', 'jofry', 'berti', \"'lifa\", 'lynney', 'zerto', 'valey', 'gissa', 'jubie']\n",
      "Epoch 13/30\n",
      "47909/47909 [==============================] - 11s 225us/step - loss: 1.6008\n",
      "['ostulle', 'valeria', 'claudis', 'orella', 'fragestar', 'hurgee', '-ugella', 'dania', '-ugan', 'lanisa']\n",
      "Epoch 14/30\n",
      "47909/47909 [==============================] - 11s 237us/step - loss: 1.5665\n",
      "['vorgin', 'renk', 'chew', 'elmet', 'ebcie', 'eleettre', 'collie', 'zorrie', 'veria', 'thelyne']\n",
      "Epoch 15/30\n",
      "47909/47909 [==============================] - 11s 224us/step - loss: 1.5355\n",
      "['giera', 'vyrne', 'xemenrik', 'gayten', 'alphissa', 'iado', 'wialde', 'quertin', 'zin', 'hel']\n",
      "Epoch 16/30\n",
      "47909/47909 [==============================] - 10s 218us/step - loss: 1.5048\n",
      "['devidea', 'eebette', '-mahis', 'zeiphian', 'yankola', 'lynnet', 'semmie', 'orilea', 'vasermanne', 'harrold']\n",
      "Epoch 17/30\n",
      "47909/47909 [==============================] - 11s 228us/step - loss: 1.4779\n",
      "['nimon', 'bisha', 'noneta', 'lacienee', 'lorissa', 'deane', 'rowell', 'foleon', 'merrel', '-uletta']\n",
      "Epoch 18/30\n",
      "47909/47909 [==============================] - 11s 223us/step - loss: 1.4527\n",
      "['quentine', 'hertie', 'lana', 'erissa', '-auna', 'isalee', 'agoree', 'eranne', 'eisjeebela', 'ruddie']\n",
      "Epoch 19/30\n",
      "47909/47909 [==============================] - 10s 212us/step - loss: 1.4333\n",
      "['bereck', 'zela', 'ingee', 'quint', 'ranna', 'beerdette', 'uisca', 'ingelbert', 'sinclare', 'xeree']\n",
      "Epoch 20/30\n",
      "47909/47909 [==============================] - 10s 210us/step - loss: 1.4100\n",
      "['vivian', 'ylos', 'wain', 'ya', 'gobpy', 'shey', 'ethela', 'iana', 'yaskie', 'onaldo']\n",
      "Epoch 21/30\n",
      "47909/47909 [==============================] - 10s 214us/step - loss: 1.3913\n",
      "['vivian', '-avelya', 'belia', 'sonni', 'lazar', 'yolanthe', 'mieta', 'marino', 'ervin', 'kendire']\n",
      "Epoch 22/30\n",
      "47909/47909 [==============================] - 11s 225us/step - loss: 1.3744\n",
      "['rosaleen', 'quigfan', 'fiff', 'ski', 'yolonte', 'ariana', 'onela', 'engiub', 'hildigau', 'win']\n",
      "Epoch 23/30\n",
      "47909/47909 [==============================] - 11s 220us/step - loss: 1.3583\n",
      "['lynd', 'myrti', 'danni', 'quinl', 'leigh', 'ilise', 'issyla', 'wylye', 'herth', \"'layton\"]\n",
      "Epoch 24/30\n",
      "47909/47909 [==============================] - 10s 218us/step - loss: 1.3417\n",
      "['agnese', 'alta', '-annelle', 'otelia', 'parbara', 'franklen', 'phel', '-margaretta', 'heathun', 'zabusta']\n",
      "Epoch 25/30\n",
      "47909/47909 [==============================] - 11s 226us/step - loss: 1.3286\n",
      "['varghal', 'faushin', \"'laurene\", 'zacharie', 'charmeis', 'herci', 'bubwi', 'meara', 'trmus', 'elpkie']\n",
      "Epoch 26/30\n",
      "47909/47909 [==============================] - 11s 233us/step - loss: 1.3144\n",
      "['ira', 'lly', 'izabel', 'fi', 'taffy', 'winnah', 'wynf', 'lauren', 'query', 'gentarus']\n",
      "Epoch 27/30\n",
      "47909/47909 [==============================] - 11s 232us/step - loss: 1.3050\n",
      "['fianna', 'quint', 'zex', 'hermon', 'anna', 'ingeberg', 'red', 'esi', 'gwendy', 'lucina']\n",
      "Epoch 28/30\n",
      "47909/47909 [==============================] - 11s 224us/step - loss: 1.2946\n",
      "['vanya', 'beitrey', 'linna', 'beaufi', 'rodd', 'elbertine', 'reymond', 'reech', 'ruby', 'erwin']\n",
      "Epoch 29/30\n",
      "47909/47909 [==============================] - 11s 232us/step - loss: 1.2831\n",
      "['comina', 'tena', 'onie', 'kalinde', '-ana', 'yalon', 'kancay', 'francey', 'kristina', 'izzy']\n",
      "Epoch 30/30\n",
      "47909/47909 [==============================] - 11s 221us/step - loss: 1.2735\n",
      "['verny', 'remilgo', 'elisabet', 'bryan', \"'laurie\", 'zoveria', 'ana', 'tianor', 'olivia', 'karthi']\n",
      "saving the model with loss = 1.2735233223379292 on epoch 29\n"
     ]
    }
   ],
   "source": [
    "hist = model.fit(X, Y, epochs=30, batch_size=128, verbose=1, callbacks=[mycallback(crp,'babynames-best.h5')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mgpu_model = multi_gpu_model(model,gpus=2)\n",
    "# mgpu_model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
    "# mgpu_model.fit(X, Y, epochs=30, batch_size=256) #, callbacks=callbacks)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-11-21T13:42:11.057Z"
    }
   },
   "outputs": [],
   "source": [
    "sorted(set(generate_text(model,crp,'gom',100)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
