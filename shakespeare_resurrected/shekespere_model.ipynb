{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center> Generate shekespere poems  by reading work using Char LSTM </center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keras with TF background"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-21T09:51:55.812831Z",
     "start_time": "2018-11-21T09:51:54.060225Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/pai/home/kmadhu/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense, Activation,Dropout\n",
    "from keras.callbacks import ModelCheckpoint,Callback\n",
    "from keras.utils import to_categorical,multi_gpu_model\n",
    "from keras.models import model_from_yaml\n",
    "from random import randint\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Corpus\n",
    "    - data    : raw string input data\n",
    "    - vocab   : vocabulary\n",
    "    - encoder : python dictionary. { 'char' : index }\n",
    "    - decoder : python dictionary. { index  : 'char'}\n",
    "    - Tx      : timestep\n",
    "    - m       : Number of samples\n",
    "    - Vx      : Length of the vocabular or Channel Length after encoding\n",
    "    - X       : Features\n",
    "    - Y       : Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-21T09:51:56.311003Z",
     "start_time": "2018-11-21T09:51:56.293416Z"
    }
   },
   "outputs": [],
   "source": [
    "class corpus:\n",
    "    def __init__(self):\n",
    "        self.data    = \"\"\n",
    "        self.vocab   = \"\"\n",
    "        \n",
    "        self.encoder = None\n",
    "        self.decoder = None\n",
    "        \n",
    "        self.Tx      = 0\n",
    "        self.m       = 0\n",
    "        self.Vx      = 0\n",
    "        \n",
    "        self.X       = []\n",
    "        self.Y       = []\n",
    "        \n",
    "    def __str__(self):\n",
    "        s = ''\n",
    "        s += f'Number of Examples  m  = {self.m}\\n'\n",
    "        s += f'Number of Timesteps Tx = {self.Tx}\\n'\n",
    "        s += f'Vocabulary Length   Vx = {self.Vx}\\n'\n",
    "        return s\n",
    "     \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-21T09:51:57.115872Z",
     "start_time": "2018-11-21T09:51:57.114114Z"
    }
   },
   "outputs": [],
   "source": [
    "# crp = corpus() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read the file to populate data and vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-21T09:51:58.884103Z",
     "start_time": "2018-11-21T09:51:58.880130Z"
    }
   },
   "outputs": [],
   "source": [
    "def load_data(fpath):\n",
    "    with open(fpath) as corpus_file:\n",
    "        data = corpus_file.read().lower()\n",
    "    vocab = sorted(list(set(data)))\n",
    "    return data,vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-21T09:51:59.547958Z",
     "start_time": "2018-11-21T09:51:59.546038Z"
    }
   },
   "outputs": [],
   "source": [
    "# crp.data,crp.vocab  = load_data('data/sonnets.txt')\n",
    "# print(\"data sample = '{}' data len = {} vocab = {} vocab_len = {}\".\n",
    "#               format(crp.data[0:20],len(crp.data), crp.vocab,len(crp.vocab)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Encoder and Decoders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-21T09:52:00.730215Z",
     "start_time": "2018-11-21T09:52:00.726237Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_encoder(crp):\n",
    "    return {c: i for i, c in enumerate(crp.vocab)}\n",
    "def get_decoder(crp):\n",
    "    return {i: c for i, c in enumerate(crp.vocab)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Slice the continous text data into list of features and Labels\n",
    " - Take first 51 char text(0..50) and keep first 50 chars as feature and last one char as label\n",
    " - Slide the window by one character i.e text(1..51) and repeat the process.\n",
    " - We will get len(data) - 50 examples\n",
    " - Tx = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-21T09:52:02.426460Z",
     "start_time": "2018-11-21T09:52:02.418243Z"
    }
   },
   "outputs": [],
   "source": [
    "def slice_data(data,timesteps):    \n",
    "    m       = len(crp.data) - timesteps\n",
    "    feature = []\n",
    "    label   = []\n",
    "    for i in range (0, m):\n",
    "        sentence  = data[i:i + timesteps]\n",
    "        next_char = data[i + timesteps]\n",
    "        feature.append(sentence)\n",
    "        label.append(next_char)\n",
    "    return feature,label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-21T09:52:03.014899Z",
     "start_time": "2018-11-21T09:52:03.013086Z"
    }
   },
   "outputs": [],
   "source": [
    "# timesteps = 50\n",
    "# crp.X,crp.Y = slice_data(crp.data,timesteps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-21T09:52:03.533984Z",
     "start_time": "2018-11-21T09:52:03.532094Z"
    }
   },
   "outputs": [],
   "source": [
    "# for i in range(3):\n",
    "#     r = randint(1,len(crp.data))\n",
    "#     print(f\"X[{r}] = {crp.X[r]} Y[{r}] = {crp.Y[r]}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Update parameters (Tx, Vx, m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-21T09:52:04.540000Z",
     "start_time": "2018-11-21T09:52:04.538122Z"
    }
   },
   "outputs": [],
   "source": [
    "# crp.Tx = timesteps\n",
    "# crp.Vx = len(crp.vocab)\n",
    "# crp.m      = len(crp.X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-21T09:52:05.036897Z",
     "start_time": "2018-11-21T09:52:05.035163Z"
    }
   },
   "outputs": [],
   "source": [
    "# print(crp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-21T07:03:01.353919Z",
     "start_time": "2018-11-21T07:03:01.352178Z"
    }
   },
   "source": [
    "## Feature Engineering\n",
    "    - Transform X data (m,Tx,Vx) to Y (m,1,Vx) i.e (m,Vx).\n",
    "    - Many to One RNN architecture\n",
    "    - Lets convert into one hot encoding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-21T10:08:56.738285Z",
     "start_time": "2018-11-21T10:08:56.721223Z"
    }
   },
   "outputs": [],
   "source": [
    "def encode_data(crp):        \n",
    "    # First each char after Tx, we will have one example.\n",
    "    feature = np.zeros((crp.m,crp.Tx))\n",
    "    label   = np.zeros(crp.m)\n",
    "        \n",
    "    for i in range (0, crp.m, 1):\n",
    "        sentence  = crp.X[i]\n",
    "        next_char = crp.Y[i]\n",
    "            \n",
    "        for j in range(crp.Tx):\n",
    "            feature[i,j] = crp.encoder[sentence[j]]\n",
    "            label[i]     = crp.encoder[next_char]\n",
    "\n",
    "    feature = to_categorical(feature,num_classes=crp.Vx)\n",
    "    label   = to_categorical(label,num_classes=crp.Vx)\n",
    "    return feature,label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-21T09:52:06.813365Z",
     "start_time": "2018-11-21T09:52:06.811091Z"
    }
   },
   "outputs": [],
   "source": [
    "# X,Y = encode_data(crp)\n",
    "\n",
    "# print(\"Sliced our corpus into {} examples. feature.shape (m,Tx,Vx) = {} label.shape (m,Vx) = {}\".\n",
    "#         format(crp.m, X.shape,Y.shape))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Model\n",
    "    - LSTM model will remove Tx dimension if you don't specify return_sequences=True.\n",
    "    - In the predict, you can pass a random text of length upto Tx to kick start the prediction. Loop it after it gives each word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-21T09:52:09.222847Z",
     "start_time": "2018-11-21T09:52:09.197364Z"
    }
   },
   "outputs": [],
   "source": [
    "def build_LSTM_model(units,Tx,Vx,layers=1,dropout=None):\n",
    "    model = Sequential()\n",
    "    for i in range(layers):\n",
    "        if(layers == 1):\n",
    "            model.add(LSTM(units, input_shape=(Tx,Vx)))\n",
    "        elif(i == 0): \n",
    "            model.add(LSTM(units, input_shape=(Tx,Vx),return_sequences=True))\n",
    "        elif(i != layers -1):\n",
    "            model.add(LSTM(units, return_sequences=True))\n",
    "        else:\n",
    "            model.add(LSTM(units))\n",
    "\n",
    "        if(dropout is not None):\n",
    "            model.add(Dropout(dropout))\n",
    "                    \n",
    "    model.add(Dense(Vx))\n",
    "    model.add(Activation('softmax'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-21T09:52:09.772897Z",
     "start_time": "2018-11-21T09:52:09.771070Z"
    }
   },
   "outputs": [],
   "source": [
    "# model = build_LSTM_model(256,crp.Tx,crp.Vx)\n",
    "# model.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference Logic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-21T09:52:10.891645Z",
     "start_time": "2018-11-21T09:52:10.858241Z"
    }
   },
   "outputs": [],
   "source": [
    "def generate_text(model, crp, seed_text,text_length):\n",
    "    def pad_seed(seed_phrase):\n",
    "        phrase_length = len(seed_phrase)\n",
    "        pattern = \"\"\n",
    "        for i in range (0, crp.Tx):\n",
    "            pattern += seed_phrase[i % phrase_length]\n",
    "        return pattern\n",
    "\n",
    "        \n",
    "    X = np.zeros((1, crp.Tx, crp.Vx), dtype=np.bool)\n",
    "    for i, character in enumerate(pad_seed(seed_text)):\n",
    "        X[0, i, crp.encoder[character]] = 1\n",
    "\n",
    "    generated_text = \"\"\n",
    "    for i in range(text_length):\n",
    "        prediction = np.argmax(model.predict(X, verbose=0))\n",
    "\n",
    "        generated_text += crp.decoder[prediction]\n",
    "\n",
    "        activations = np.zeros((1, 1, crp.Vx), dtype=np.bool)\n",
    "        activations[0, 0, prediction] = 1\n",
    "        X = np.concatenate((X[:, 1:, :], activations), axis=1)\n",
    "\n",
    "    return generated_text\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom call back to save the final best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-21T09:52:41.473725Z",
     "start_time": "2018-11-21T09:52:41.450934Z"
    }
   },
   "outputs": [],
   "source": [
    "class mycallback(Callback):\n",
    "    def __init__(self,model_path):\n",
    "        super(mycallback, self).__init__()\n",
    "        self.best_model = None\n",
    "        self.best_loss  = 1000\n",
    "        self.best_epoch = -1\n",
    "        self.model_path = model_path\n",
    "        \n",
    "    def on_train_end(self, logs={}):\n",
    "        print(f'saving the model with loss = {self.best_loss} on epoch {self.best_epoch}')\n",
    "        self.best_model.save(self.model_path)\n",
    "        return\n",
    " \n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        loss = logs['loss']\n",
    "        if(loss < self.best_loss):\n",
    "            self.best_model = self.model\n",
    "            self.best_loss  = loss\n",
    "            self.best_epoch = epoch\n",
    "            print(generate_text(self.model,crp,'hello',100))\n",
    "        return \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-21T09:52:15.540970Z",
     "start_time": "2018-11-21T09:52:15.539102Z"
    }
   },
   "outputs": [],
   "source": [
    "# hist = model.fit(X, Y, epochs=2, batch_size=128, callbacks=[mycallback('shekespere_model-best.h5')])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <center> Execution </center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and Preprocess Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-21T10:09:15.958711Z",
     "start_time": "2018-11-21T10:09:13.613540Z"
    }
   },
   "outputs": [],
   "source": [
    "crp                 = corpus()\n",
    "crp.data,crp.vocab  = load_data('data/sonnets.txt')\n",
    "crp.encoder         = get_encoder(crp)\n",
    "crp.decoder         = get_decoder(crp)\n",
    "\n",
    "\n",
    "timesteps           = 50\n",
    "crp.X,crp.Y         = slice_data(crp.data,timesteps)\n",
    "crp.Tx              = timesteps\n",
    "crp.Vx              = len(crp.vocab)\n",
    "crp.m               = len(crp.X)\n",
    "\n",
    "X,Y = encode_data(crp)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-21T09:06:22.676658Z",
     "start_time": "2018-11-21T09:06:22.674682Z"
    }
   },
   "source": [
    "## create the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-21T10:09:18.352984Z",
     "start_time": "2018-11-21T10:09:18.063464Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_2 (LSTM)                (None, 256)               302080    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 38)                9766      \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 38)                0         \n",
      "=================================================================\n",
      "Total params: 311,846\n",
      "Trainable params: 311,846\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = build_LSTM_model(256,crp.Tx,crp.Vx)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-21T10:41:48.546902Z",
     "start_time": "2018-11-21T10:09:21.639475Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "94601/94601 [==============================] - 64s 675us/step - loss: 2.5182\n",
      "ve the thee sore the thee sore the thee sore the thee sore the thee sore the thee sore the thee sore\n",
      "Epoch 2/30\n",
      "94601/94601 [==============================] - 61s 648us/step - loss: 2.0627\n",
      " seall seall seall seall the sealt,\n",
      "the seal se the seall seall seall seall the thee the sealt,\n",
      "the \n",
      "Epoch 3/30\n",
      "94601/94601 [==============================] - 64s 679us/step - loss: 1.8857\n",
      "ng thee,\n",
      "and the will the will the will the will thee thee,\n",
      "the will the will the will the will thee\n",
      "Epoch 4/30\n",
      "94601/94601 [==============================] - 64s 674us/step - loss: 1.7717\n",
      "ng thee,\n",
      "and the come the come the come the corter,\n",
      "and the come the come the come the come thee,\n",
      "an\n",
      "Epoch 5/30\n",
      "94601/94601 [==============================] - 64s 675us/step - loss: 1.6875\n",
      "ng.\n",
      "\n",
      "for the world in the world in the world in thee,\n",
      "when i an the world in the world in thee,\n",
      "wher\n",
      "Epoch 6/30\n",
      "94601/94601 [==============================] - 64s 674us/step - loss: 1.6192\n",
      "ng.\n",
      "\n",
      "the sonters in the self the prien the store,\n",
      "the senter in the self the prien the store,\n",
      "the se\n",
      "Epoch 7/30\n",
      "94601/94601 [==============================] - 62s 659us/step - loss: 1.5619\n",
      "ng,\n",
      "and the with the world the world the world should bearther's bearther bearther bearther's bearth\n",
      "Epoch 8/30\n",
      "94601/94601 [==============================] - 61s 643us/step - loss: 1.5020\n",
      "n.\n",
      "\n",
      "the world should thee i am thee i am thee,\n",
      "  then though should thee i am thee i am thee,\n",
      "  then\n",
      "Epoch 9/30\n",
      "94601/94601 [==============================] - 62s 660us/step - loss: 1.4450\n",
      "ng.\n",
      "\n",
      "then thou art the strengs with still doth lies,\n",
      "that i have sweet some shall beauty still,\n",
      "and \n",
      "Epoch 10/30\n",
      "94601/94601 [==============================] - 61s 648us/step - loss: 1.3916\n",
      "ng.\n",
      "\n",
      "when that she that the world with the storn,\n",
      "and then the beauty of the world of thee,\n",
      "and ther\n",
      "Epoch 11/30\n",
      "94601/94601 [==============================] - 63s 666us/step - loss: 1.3334\n",
      "ng.\n",
      "o! that shall thou art the store the clook of mind,\n",
      "and then the world with this spirity stain,\n",
      "\n",
      "Epoch 12/30\n",
      "94601/94601 [==============================] - 65s 683us/step - loss: 1.2785\n",
      "ng.\n",
      "o! that i have sweet self to be receivest\n",
      "the world with thine eyes the world with thee shows,\n",
      " \n",
      "Epoch 13/30\n",
      "94601/94601 [==============================] - 63s 663us/step - loss: 1.2188\n",
      "ns.\n",
      "  sunce i not to the best of the sen to thee.\n",
      "\n",
      "when i have sweet strengthent of the restress'd,\n",
      "\n",
      "Epoch 14/30\n",
      "94601/94601 [==============================] - 62s 658us/step - loss: 1.1615\n",
      "ns.\n",
      "  so long as the thought of all me to thee.\n",
      "\n",
      "when thou art that the world with the true\n",
      "that i h\n",
      "Epoch 15/30\n",
      "94601/94601 [==============================] - 63s 669us/step - loss: 1.1015\n",
      "ng:\n",
      "  lost that well thou art the strength of love.\n",
      "\n",
      "when that my love summer's from the day,\n",
      "the de\n",
      "Epoch 16/30\n",
      "94601/94601 [==============================] - 62s 657us/step - loss: 1.0445\n",
      "ng:\n",
      "against that which the reserve the cloces it,\n",
      "and even the substance stoll the clock the mind,\n",
      "a\n",
      "Epoch 17/30\n",
      "94601/94601 [==============================] - 63s 669us/step - loss: 0.9873\n",
      "ng:\n",
      "from theef anter to sue i behold thee,\n",
      "when in dead need words in death there are,\n",
      "and therefore\n",
      "Epoch 18/30\n",
      "94601/94601 [==============================] - 64s 674us/step - loss: 0.9348\n",
      "nge.\n",
      "  then thou art thy sweet love's sweet self to thee.\n",
      "\n",
      "when thou art for my sightless of thy swe\n",
      "Epoch 19/30\n",
      "94601/94601 [==============================] - 63s 666us/step - loss: 0.8842\n",
      "nger.\n",
      "goling his since more true thine own still,\n",
      "to thy self thy sweet self to be remember'd\n",
      "the be\n",
      "Epoch 20/30\n",
      "94601/94601 [==============================] - 63s 667us/step - loss: 0.8362\n",
      "ng,\n",
      "and summer's strepgiver of the store,\n",
      "when i am now proud time than ten times fare sun\n",
      "the muse \n",
      "Epoch 21/30\n",
      "94601/94601 [==============================] - 62s 655us/step - loss: 0.7922\n",
      "ne.\n",
      "  so thou wilt live to conse on thee hast being made,\n",
      "shall needs no preingur your praise contin\n",
      "Epoch 22/30\n",
      "94601/94601 [==============================] - 63s 668us/step - loss: 0.7512\n",
      "nge.\n",
      "  then that will good on despised wo deve see,\n",
      "  as thou are in my self all to stare most.\n",
      "  an\n",
      "Epoch 23/30\n",
      "94601/94601 [==============================] - 63s 661us/step - loss: 0.7098\n",
      "ne.\n",
      "  then that we mest me that we mure me tonge.\n",
      "\n",
      "so thou shalt not the fairest confounds heart.\n",
      "i \n",
      "Epoch 24/30\n",
      "94601/94601 [==============================] - 64s 676us/step - loss: 0.6763\n",
      "ne.\n",
      "  there ore confunes of thy self i wrong,\n",
      "  and thou in this muse, and thou mayst pait\n",
      "from mand\n",
      "Epoch 25/30\n",
      "94601/94601 [==============================] - 63s 671us/step - loss: 0.6468\n",
      "n'st,\n",
      "and sweet toon myself, but to you fell a dot,\n",
      "save after that fair that some sumpess,\n",
      "and trul\n",
      "Epoch 26/30\n",
      "94601/94601 [==============================] - 62s 657us/step - loss: 0.6127\n",
      "ning,\n",
      "and sumperit his spity in thy state,\n",
      "thou hast to brave you with my foith of love,\n",
      "a doth my s\n",
      "Epoch 27/30\n",
      "94601/94601 [==============================] - 64s 675us/step - loss: 0.5850\n",
      "ne,\n",
      "  betaid this muge grav'd first my heart how to me.\n",
      "in thy beauty's sumpess to the may decaie,\n",
      "w\n",
      "Epoch 28/30\n",
      "94601/94601 [==============================] - 63s 665us/step - loss: 0.5588\n",
      "ne,\n",
      "a same that i am the filld thy dearert\n",
      "have hath my memin thy heart's fuls is past,\n",
      "save all my \n",
      "Epoch 29/30\n",
      "94601/94601 [==============================] - 60s 634us/step - loss: 0.5355\n",
      "ne,\n",
      "and to the lears of love, not sight seek\n",
      "no fair with find ancelancy tomp his cannot?\n",
      "i see the \n",
      "Epoch 30/30\n",
      "94601/94601 [==============================] - 62s 658us/step - loss: 0.5122\n",
      "ng's.\n",
      "the lively versance i long of bear,\n",
      "which shall by blage doth put one in surmere,\n",
      "the world th\n",
      "saving the model with loss = 0.5121634670952695 on epoch 29\n"
     ]
    }
   ],
   "source": [
    "hist = model.fit(X, Y, epochs=30, batch_size=128, verbose=1, callbacks=[mycallback('shekespere_model-best.h5')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-11-21T09:42:45.223Z"
    }
   },
   "outputs": [],
   "source": [
    "# mgpu_model = multi_gpu_model(model,gpus=2)\n",
    "# mgpu_model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
    "# mgpu_model.fit(X, Y, epochs=30, batch_size=256) #, callbacks=callbacks)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-21T11:10:16.647306Z",
     "start_time": "2018-11-21T11:10:07.287590Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y givgr\n",
      "s my tomb true sings so prige to thee,\n",
      "or who choughts of death, or why should it is,\n",
      "and every foul world as feed of bearty,\n",
      "and beauty shall be most that thou forged'st,\n",
      "let thou all the world that thou desert'st rangmenge.\n",
      "  let me have falles than the world may shart,\n",
      "  though in thy breast, when you in me well brow,\n",
      "  thin that she that which is he thine eyes were short;\n",
      "but then my fairest, and therefore to be.\n",
      "is in thy beauty than your poet conting,\n",
      "and yet i consider of your lif\n"
     ]
    }
   ],
   "source": [
    "print(generate_text(model,crp,'hlo',500))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
